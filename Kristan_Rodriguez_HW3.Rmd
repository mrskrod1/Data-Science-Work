---
output:
  html_document: default
  pdf_document: default
---
# Intro to Data Science - HW 3
##### Copyright Jeffrey Stanton, Jeffrey Saltz, and Jasmina Tacheva


```{r}
# Enter your name here: Kristan Rodriguez
```

### Attribution statement: (choose only one and delete the rest)


```{r}
# 1. I did this homework by myself, with help from the book and the professor.
# 2. I did this homework with help from the book and the professor and these Internet sources:
#3. I did this homework with the help of another student, but reserved academic integrity and did not copy and paste answers.
```

### Reminders of things to practice from last week: 
Make a data frame		data.frame( ) <br>
Row index of max/min	which.max( )  which.min( )<br>
Sort value or order rows	sort( )   order( )<br>
Descriptive statistics 	mean( ) sum( ) max( ) <br>
Conditional statement	if (condition) “true stuff” else “false stuff”<br>

### This Week: 
Often, when you get a dataset, it is not in the format you want. You can (and should) use code to refine the dataset to become more useful. As Chapter 6 of Introduction to Data Science mentions, this is called “data munging.” In this homework, you will read in a dataset from the web and work on it (in a data frame) to improve its usefulness.


## Part 1: Use read_csv( ) to read a CSV file from the web into a data frame:

A.	Use R code to read directly from a URL on the web. Store the dataset into a new dataframe, called dfComps. <br>
The URL is:    <br>
"https://intro-datascience.s3.us-east-2.amazonaws.com/companies1.csv" <br>
**Hint:** use read_csv( ), not read.csv( ). This is from the **tidyverse package**. Check the help to compare them.



```{r}
#View(companies1)
#dfComps<-read_csv ("companies1.csv")
#dfComps<-companies1
```

## Part 2: Create a new data frame that only contains companies with a homepage URL:

E.	Use **subsetting** to create a new dataframe that contains only the companies with homepage URLs (store that dataframe in **urlComps**).


```{r}
library(tidyverse)
library(stringi)
#urlComps<- filter(dfComps, !is.na(homepage_url))

```

D.	How many companies are missing a homepage URL?


```{r}
#summary(is.na(dfComps$homepage_url))
```

## Part 3: Analyze the numeric variables in the dataframe.

G.	How many **numeric variables** does the dataframe have? You can figure that out by looking at the output of **str(urlComps)**. 

H.	What is the average number of funding rounds for the companies in **urlComps**?


```{r}
#str(urlComps)
#glimpse(urlComps)
#mean(dfComps$funding_rounds)
#urlComps %>%
 # group_by(urlComps$name) %>%
  #summarize(mean=mean(urlComps$funding_rounds))
#urlComps %>%
 # select(urlComps$name, urlComps$funding_rounds)
```

I.	What year was the oldest company in the dataframe founded? <br>
**Hint:** If you get a value of “NA,” most likely there are missing values in this variable which preclude R from properly calculating the min & max values. You can ignore NAs with basic math calculations. For example, instead of running mean(urlComps$founded_year), something like this will work for determining the average (note that this question needs to use a different function than 'mean'. 


```{r}
#mean(urlComps$founded_year, na.rm=TRUE)

#min(urlComps$founded_year,  na.rm=TRUE) 
```

## Part 4:  Use string operations to clean the data.

K.	The **permalink variable** in **urlComps** contains the name of each company but the names are currently preceded by the prefix “/organization/”. We can use str_replace() in tidyverse or gsub() to clean the values of this variable:


```{r}
#View(urlComps$permalink)
#urlComps$permalink<- gsub("\\/organization/"," ",
                          #as.character(urlComps$permalink))
#View(urlComps)
#urlComps$permalink<- gsub("\\//"," ",
                          #as.character(urlComps$permalink))
```

L.	Can you identify another variable which should be numeric but is currently coded as character? Use the as.numeric() function to add a new variable to **urlComps** which contains the values from the char variable as numbers. Do you notice anything about the number of NA values in this new column compared to the original “char” one?  


```{r}
#urlComps$funding_total_usd<-as.numeric(gsub(",","",
                            #urlComps$funding_total_usd))
```


N. You are now ready to convert **urlComps$funding_new** to numeric using as.numeric(). 

Calculate the average funding amount for **urlComps**. If you get “NA,” try using the **na.rm=TRUE** argument from problem I.


```{r}
#urlComps$funding_new<- as.numeric(gsub(",", "",
                                       #urlComps$funding_new))
#avgFunding<- mean(urlComps$funding_new, na.rm=TRUE)
#avgFunding
```

Sample three unique observations from urlComps$funding_rounds, store the results in the vector 'observations'


```{r}
#set.seed(1)
#observation<-sample(urlComps$funding_rounds, size=3, replace=TRUE)
```

Take the mean of those observations


```{r}
#mean(sample(urlComps$funding_rounds, size=3, replace=TRUE))
```

Do the two steps (sampling and taking the mean) in one line of code


```{r}
#replicate(100, mean(sample(urlComps$funding_rounds, size=3, replace=TRUE)), simplify=TRUE)
```

Explain why the two means are (or might be) different
# When you take a random sample of numbers each time it will be different numbers and that's why the mean will vary.
Use the replicate( ) function to repeat your sampling of three observations of urlComps$funding_rounds  observations five times. The first argument to replicate( ) is the number of repeats you want. The second argument is the little chunk of code you want repeated.


```{r}
#mean(replicate(5, mean(sample(urlComps$funding_rounds, size=3, replace=TRUE)), simplify=TRUE))

```

Rerun your replication, this time doing 20 replications and storing the output of replicate() in a variable called **values**.


```{r}
#values<-mean(replicate(20, mean(sample(urlComps$funding_rounds, size=3, replace=TRUE)), simplify=TRUE))


```

Generate a **histogram** of the means stored in **values**. 


```{r}
#hist(replicate(20, mean(sample(urlComps$funding_rounds, size=3, replace=TRUE)), simplify=TRUE),
     #main="Sampling Distributions: 20 means",
     #xlab="Means of funding_rounds")
```

Rerun your replication, this time doing 1000 replications and storing the output of replicate() in a variable called **values**, and then generate a histogram of **values**.


```{r}
#values<-mean(replicate(1000, mean(sample(urlComps$funding_rounds, size=3, replace=TRUE)), simplify=TRUE))

#hist(replicate(1000, mean(sample(urlComps$funding_rounds, size=3, replace=TRUE)), simplify=TRUE),
     #main="Sampling Distributions: 20 means",
     #xlab="Means of funding_rounds")
```

Repeat the replicated sampling, but this time, raise your sample size from 3 to 22. How does that affect your histogram? Explain in a comment.


```{r}
#values1<-mean(replicate(1000, mean(sample(urlComps$funding_rounds, size=22, replace=TRUE)), simplify=TRUE))


#hist(replicate(1000, mean(sample(urlComps$funding_rounds, size=22, replace=TRUE)), simplify=TRUE),
     #main="Sampling Distributions: 20 means",
     #xlab="Means of funding_rounds")

#The histogram takes on a more normal curve because of the increase in sample size.
```

Explain in a comment below, the last three histograms, why do they look different?


```{r}
#The last three histograms looked different due to the number of replications increasing and then the sample size increasing. This is due to the law of large numbers. Meaning the larger the sample size the closer to the actual population mean you get. 
```
